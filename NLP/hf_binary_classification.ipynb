{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZcXrPMrEzslt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1102796d-773d-44b4-c3ad-6d3ab0d5e88f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 585 kB 36.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 419 kB 54.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 141 kB 55.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 56.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 35.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 35.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 14.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 365 kB 36.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 76.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 71.2 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 13.1 MB 29.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 34.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 274 kB/s \n",
            "\u001b[K     |████████████████████████████████| 86 kB 7.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.9 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 65.2 MB/s \n",
            "\u001b[?25h  Building wheel for optimum (PEP 517) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-lightning --quiet\n",
        "!pip install transformers --quiet\n",
        "!pip install datasets --quiet\n",
        "!pip install onnx --quiet\n",
        "!pip install onnxruntime --quiet\n",
        "!pip install optimum --quiet"
      ],
      "id": "ZcXrPMrEzslt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fb65d86"
      },
      "outputs": [],
      "source": [
        "# read data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "7fb65d86"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e768a0d",
        "outputId": "f87b81f0-8396-4102-b997-dd5ba35aaaa4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1384, 3722)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df1=pd.read_excel('/content/Covid humour data.xlsx',0)\n",
        "df2=pd.read_excel('/content/Covid humour data.xlsx',1)\n",
        "len(df1),len(df2)\n"
      ],
      "id": "1e768a0d"
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.concat([df1.iloc[:,0],df2.iloc[:,0]],axis=0)\n",
        "df=df.reset_index()\n",
        "df['label']=pd.Series([0]*len(df1)+[1]*len(df2))\n",
        "df.drop('index',axis=1,inplace=True)\n",
        "df.columns=['tweet','label']\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LhoN1bjwQr2H",
        "outputId": "4b3ec03b-f539-4202-bcc9-dc8685aefcb0"
      },
      "id": "LhoN1bjwQr2H",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               tweet  label\n",
              "0  We can look at the damage made by “COVID-19”, ...      0\n",
              "1  What's got 400 legs and 7 teeth?... The queue ...      0\n",
              "2  Chuck Norris got the Coronavirus. The virus is...      0\n",
              "3  I heard a new term today: when were you born? ...      0\n",
              "4  Why did the Coronavirus cross the street?... ....      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6dfb902-b4ab-435c-a36c-6773734bd6f7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>We can look at the damage made by “COVID-19”, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What's got 400 legs and 7 teeth?... The queue ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Chuck Norris got the Coronavirus. The virus is...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I heard a new term today: when were you born? ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Why did the Coronavirus cross the street?... ....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6dfb902-b4ab-435c-a36c-6773734bd6f7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e6dfb902-b4ab-435c-a36c-6773734bd6f7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e6dfb902-b4ab-435c-a36c-6773734bd6f7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df476101",
        "outputId": "9d6366de-888c-4b81-c865-db0875319277"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  \"\"\"\n"
          ]
        }
      ],
      "source": [
        "def clean(tweets):\n",
        "    tweets.tweet=tweets.tweet.str.replace(r'@user', '', regex=True)\n",
        "    tweets.tweet=tweets.tweet.str.lower()\n",
        "    tweets.tweet=tweets.tweet.str.replace(r'[^\\w\\s]+', '')\n",
        "    tweets.tweet=tweets.tweet.str.replace(r'\\s\\s+', '')\n",
        "    tweets.tweet=tweets.tweet.str.strip()\n",
        "    return tweets\n",
        "df=clean(df)\n"
      ],
      "id": "df476101"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3666c1e1"
      },
      "outputs": [],
      "source": [
        "df.drop_duplicates(inplace=True)"
      ],
      "id": "3666c1e1"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "768c87ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbb76401-c254-4744-b737-e8721aac6fc3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "df.duplicated().sum()"
      ],
      "id": "768c87ff"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "74a1d979",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "3bb5a3de-f316-4449-e95d-1cc903ec88c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  tweet  label\n",
              "5101  35 new cases and 2 new deaths in somalia2106 g...      1\n",
              "5102  9474 new cases and 136 new deaths in peru2101 ...      1\n",
              "5103  breaking india added nearly 79000 fresh cases ...      1\n",
              "5104  63 new cases and 1 new death in mozambique2054...      1\n",
              "5105  210 new cases and 4 new deaths in namibia2048 ...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39e020a9-5147-43c0-9b3b-39a6555f8170\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5101</th>\n",
              "      <td>35 new cases and 2 new deaths in somalia2106 g...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5102</th>\n",
              "      <td>9474 new cases and 136 new deaths in peru2101 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5103</th>\n",
              "      <td>breaking india added nearly 79000 fresh cases ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5104</th>\n",
              "      <td>63 new cases and 1 new death in mozambique2054...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5105</th>\n",
              "      <td>210 new cases and 4 new deaths in namibia2048 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39e020a9-5147-43c0-9b3b-39a6555f8170')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-39e020a9-5147-43c0-9b3b-39a6555f8170 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-39e020a9-5147-43c0-9b3b-39a6555f8170');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "df.tail()"
      ],
      "id": "74a1d979"
    },
    {
      "cell_type": "code",
      "source": [
        "df.label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd93mJMnR2ad",
        "outputId": "b0633f24-0f38-42dd-85b5-8eb4e16be8ff"
      },
      "id": "Wd93mJMnR2ad",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    3697\n",
              "0    1170\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "QXr8Fwgj5F36"
      },
      "outputs": [],
      "source": [
        "g = df.groupby('label')\n",
        "df=g.apply(lambda x: x.sample(g.size().min(),random_state=1).reset_index(drop=True)).reset_index(drop=True)"
      ],
      "id": "QXr8Fwgj5F36"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "c33bc217",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8293894a-4679-4d29-cfe3-54014c602442"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1872, 468)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df,val_df=train_test_split(df,test_size=0.2,random_state=0)\n",
        "train_df.reset_index(inplace=True,drop=True)\n",
        "val_df.reset_index(inplace=True,drop=True)\n",
        "len(train_df),len(val_df)"
      ],
      "id": "c33bc217"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "a939dcdf"
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning import seed_everything, LightningModule, Trainer\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "from torch.nn.functional import cross_entropy\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import torch.nn as nn\n",
        "import torchmetrics\n",
        "from sklearn.metrics import classification_report,precision_recall_fscore_support,accuracy_score\n",
        "import torch#pytorch\n",
        "from transformers import AutoModelForSequenceClassification\n"
      ],
      "id": "a939dcdf"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "c4f81f70"
      },
      "outputs": [],
      "source": [
        "model_name=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "from transformers import AutoTokenizer, AutoModel#for embeddings\n",
        "# create data loader \n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "class DataReader(Dataset):\n",
        "  def __init__(self,dataframe,test=False):\n",
        "    super(DataReader,self).__init__()\n",
        "   # self.tokenizer=tokenizer\n",
        "    self.df=dataframe\n",
        "    self.test=test\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(model_name,local_files_only=False)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    text=self.df.tweet[index]\n",
        "    tokens=self.tokenizer(text,max_length=64,padding='max_length',truncation=True,return_tensors='pt')\n",
        "    if self.test:#no labels\n",
        "      return tokens.input_ids,tokens.attention_mask\n",
        "    else:\n",
        "      label=self.df.label[index]\n",
        "      return tokens.input_ids,tokens.attention_mask,label\n",
        "\n"
      ],
      "id": "c4f81f70"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "c781af02"
      },
      "outputs": [],
      "source": [
        "class OurModel(LightningModule):\n",
        "    def __init__(self ):\n",
        "        super(OurModel,self).__init__()\n",
        "      \n",
        "  \n",
        "        #pretrained model\n",
        "        self.bertmodel=AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "        #parameters\n",
        "        self.lr =5e-5\n",
        "        self.batch_size=4\n",
        "        self.numworker=2\n",
        "        self.train_acc = torchmetrics.Accuracy()\n",
        "        self.val_acc = torchmetrics.Accuracy()\n",
        "         \n",
        "        self.criterion=nn.CrossEntropyLoss()\n",
        "        self.ground_label,self.predicted_label=0,0\n",
        "        self.report=[]\n",
        "    def forward(self,input_ids,attention_mask):\n",
        "        out=self.bertmodel(input_ids.squeeze(1),attention_mask.squeeze(1)).logits\n",
        "        return out\n",
        "    \n",
        "\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.AdamW(params=self.parameters(),lr=self.lr )\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(DataReader(train_df), batch_size = self.batch_size,\n",
        "                          num_workers=self.numworker,pin_memory=True, shuffle=False,\n",
        "                         \n",
        "                         )\n",
        "\n",
        "    def training_step(self,batch,batch_idx):\n",
        "        input_ids,attention_mask,label=batch\n",
        "        out=self.forward(input_ids,attention_mask)\n",
        "        loss=self.criterion(out,label)\n",
        "        acc=self.train_acc(out,label)\n",
        "        return {'loss':loss,'acc':acc}\n",
        "    \n",
        "    def training_epoch_end(self, outputs):\n",
        "        loss=torch.stack([x[\"loss\"] for x in outputs]).mean().detach().cpu().numpy().round(2)\n",
        "        acc=torch.stack([x[\"acc\"] for x in outputs]).mean().detach().cpu().numpy().round(2)\n",
        "        self.log('train_loss', loss)\n",
        "        self.log('train_acc',acc)\n",
        "             \n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(DataReader(val_df), batch_size = self.batch_size,\n",
        "                          num_workers=self.numworker,pin_memory=True,  shuffle=False)\n",
        "    \n",
        "    def validation_step(self,batch,batch_idx):\n",
        "        input_ids,attention_mask,label=batch\n",
        "        out=self(input_ids,attention_mask)\n",
        "        loss=self.criterion(out,label)\n",
        "        acc=self.train_acc(out,label)\n",
        "        return {'loss':loss,'acc':acc,'pred':out,'label':label}\n",
        "    \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        loss=torch.stack([x[\"loss\"] for x in outputs]).mean().detach().cpu().numpy().round(2)\n",
        "        acc=torch.stack([x[\"acc\"] for x in outputs]).mean().detach().cpu().numpy().round(2)\n",
        "        print('validation accuracy',acc)\n",
        "        \n",
        "        self.log('val_loss', loss)\n",
        "        self.log('val_acc',acc)\n",
        "\n",
        "        \n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(DataReader(val_df), batch_size = self.batch_size,\n",
        "                          num_workers=self.numworker,pin_memory=True,shuffle=False)\n",
        "\n",
        "    def test_step(self,batch,batch_idx):\n",
        "        input_ids,attention_mask,label=batch\n",
        "        out=self(input_ids,attention_mask)\n",
        "        return {'pred':out,'label':label}\n",
        "    def test_epoch_end(self, outputs):\n",
        "        pred=torch.cat([x[\"pred\"] for x in outputs]).detach().cpu().numpy()\n",
        "        label=torch.cat([x[\"label\"] for x in outputs]).detach().cpu().numpy().ravel()\n",
        "        self.ground_label=label\n",
        "        self.predicted_label=pred\n",
        "        pred=np.argmax(pred,1)\n",
        "        self.report=classification_report(label,pred)\n"
      ],
      "id": "c781af02"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ecff4b3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d97383cd-53a7-41db-a63c-95d659da317f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 0\n",
            "Using 16bit native Automatic Mixed Precision (AMP)\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/callback_connector.py:97: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=0)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
            "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation accuracy 0.99\n",
            "validation accuracy 1.0\n",
            "validation accuracy 0.99\n"
          ]
        }
      ],
      "source": [
        "model=OurModel()\n",
        "seed_everything(0)\n",
        "trainer = Trainer(max_epochs=3, \n",
        "                  deterministic=True,\n",
        "                  gpus=1,precision=16,\n",
        "                  num_sanity_val_steps=0,\n",
        "#                   accumulate_grad_batches=2,\n",
        "                  enable_model_summary=False,\n",
        "                  enable_progress_bar = False,\n",
        "                  progress_bar_refresh_rate=0\n",
        "             )\n",
        "trainer.fit(model)"
      ],
      "id": "ecff4b3f"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "07e2bc12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d74ecab-546a-4ac9-e69b-4c7527b7b3f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation accuracy 0.99\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "         val_acc            0.9900000095367432\n",
            "        val_loss           0.009999999776482582\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "CPU times: user 2.31 s, sys: 1.21 s, total: 3.51 s\n",
            "Wall time: 3.67 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'val_acc': 0.9900000095367432, 'val_loss': 0.009999999776482582}]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "%%time\n",
        "trainer.validate(model)"
      ],
      "id": "07e2bc12"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "075fc734",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54c1cf71-7cc9-40f6-f55c-dfa35a2b065d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "trainer.test(model)"
      ],
      "id": "075fc734"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "aa622c4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceb7af5b-bdf7-4fb6-bc21-733cfad6b33c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       240\n",
            "           1       0.99      1.00      0.99       228\n",
            "\n",
            "    accuracy                           0.99       468\n",
            "   macro avg       0.99      0.99      0.99       468\n",
            "weighted avg       0.99      0.99      0.99       468\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(model.report)"
      ],
      "id": "aa622c4a"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "5f3e2b04"
      },
      "outputs": [],
      "source": [
        "torch.save(model.bertmodel.state_dict(), 'bert.pth')"
      ],
      "id": "5f3e2b04"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qH3mr--2E9E"
      },
      "source": [
        "# optimum"
      ],
      "id": "5qH3mr--2E9E"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "5zcA5pDw2J8b"
      },
      "outputs": [],
      "source": [
        "#save\n",
        "token=AutoTokenizer.from_pretrained(model_name,local_files_only=False)\n",
        "token.save_pretrained(\"model\")\n",
        "model.bertmodel.save_pretrained(\"model\")\n"
      ],
      "id": "5zcA5pDw2J8b"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "PpCElSF72NKW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "995e9417-881d-488f-c612-0500a41b72ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/distilbert/modeling_distilbert.py:215: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  mask, torch.tensor(torch.finfo(scores.dtype).min)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('model-quantized.onnx')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "#create optimum onnx\n",
        "from optimum.onnxruntime.configuration import AutoQuantizationConfig\n",
        "from optimum.onnxruntime import ORTQuantizer\n",
        "\n",
        "\n",
        "# The type of quantization to apply\n",
        "qconfig = AutoQuantizationConfig.arm64(is_static=False, per_channel=False)\n",
        "quantizer = ORTQuantizer.from_pretrained('model', feature=\"sequence-classification\")\n",
        "\n",
        "##Quantize the model!\n",
        "quantizer.export(\n",
        "    onnx_model_path=\"model.onnx\",\n",
        "    onnx_quantized_model_output_path=\"model-quantized.onnx\",\n",
        "    quantization_config=qconfig,\n",
        ")"
      ],
      "id": "PpCElSF72NKW"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "GUtQ7dAp20Lc"
      },
      "outputs": [],
      "source": [
        "# testing result\n",
        "from functools import partial\n",
        "from datasets import Dataset\n",
        "from optimum.onnxruntime.model import ORTModel\n",
        "from optimum.onnxruntime import ORTQuantizer\n",
        "\n",
        "# Load quantized model\n",
        "quantizer = ORTQuantizer.from_pretrained('model', feature=\"sequence-classification\")\n",
        "\n",
        "ort_model = ORTModel(\"model.onnx\", quantizer._onnx_config)"
      ],
      "id": "GUtQ7dAp20Lc"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "modO8H4P21dk"
      },
      "outputs": [],
      "source": [
        "# # %%time\n",
        "\n",
        "\n",
        "# # Create a dataset or load one from the Hub\n",
        "# ds = Dataset.from_dict({\"sentence\": list(val_df.tweet)})\n",
        "# # Tokenize the inputs\n",
        "# def preprocess_fn(ex, tokenizer):\n",
        "#     return tokenizer(ex[\"sentence\"],max_length=64,padding='max_length',truncation=True,)\n",
        "\n",
        "# tokenized_ds = ds.map(partial(preprocess_fn, tokenizer=quantizer.tokenizer))\n",
        "# ort_outputs = ort_model.evaluation_loop(tokenized_ds)\n",
        "# # Extract logits!\n",
        "# pred=ort_outputs.predictions\n"
      ],
      "id": "modO8H4P21dk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1Ez0IIy26Ld"
      },
      "outputs": [],
      "source": [
        "# from sklearn.metrics import classification_report\n",
        "# print(classification_report(val_df.label,np.argmax(pred,1)))"
      ],
      "id": "W1Ez0IIy26Ld"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHdTg_5u3Ju8"
      },
      "source": [
        "# onnx "
      ],
      "id": "rHdTg_5u3Ju8"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "UJDO70u63Kmu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ea47004-30a3-4e3a-89c4-9a808229dc75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using framework PyTorch: 1.12.0+cu113\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/distilbert/modeling_distilbert.py:215: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  mask, torch.tensor(torch.finfo(scores.dtype).min)\n",
            "Validating ONNX model...\n",
            "\t-[✓] ONNX model output names match reference model ({'logits'})\n",
            "\t- Validating ONNX Model output \"logits\":\n",
            "\t\t-[✓] (2, 2) matches (2, 2)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "All good, model saved at: onnx/model.onnx\n"
          ]
        }
      ],
      "source": [
        "!python -m transformers.onnx --model=model --feature=sequence-classification onnx/"
      ],
      "id": "UJDO70u63Kmu"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "qNyNvFNc3cI2"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from onnxruntime import InferenceSession\n",
        "model_name=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "session = InferenceSession(\"onnx/model.onnx\")\n",
        "session.intra_op_num_threads = 12\n"
      ],
      "id": "qNyNvFNc3cI2"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "KTo4Dc1M3hGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a060296e-1c91-4ff4-b419-26fd95492e8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 38.5 s, sys: 316 ms, total: 38.8 s\n",
            "Wall time: 38.6 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "tokens=tokenizer(list(val_df.tweet),max_length=64,padding='max_length',truncation=True, return_tensors=\"np\")\n",
        "outputs = session.run(output_names=[\"logits\"], input_feed=dict(tokens))"
      ],
      "id": "KTo4Dc1M3hGd"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "DTGeVzT63was",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5f674b5-bfc4-4b8b-87b4-767ac524403d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       240\n",
            "           1       0.99      1.00      0.99       228\n",
            "\n",
            "    accuracy                           0.99       468\n",
            "   macro avg       0.99      0.99      0.99       468\n",
            "weighted avg       0.99      0.99      0.99       468\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(val_df.label,np.argmax(outputs[0],1)))"
      ],
      "id": "DTGeVzT63was"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "_6RJN7xW4TSa"
      },
      "outputs": [],
      "source": [
        ""
      ],
      "id": "_6RJN7xW4TSa"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "bert_binary_classification.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}